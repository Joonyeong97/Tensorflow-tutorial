{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://jovianlin.io/embeddings-in-keras/\n",
    "# 참고사이트\n",
    "import re\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, Bidirectional, LSTM\n",
    "docs = ['Well done!', 'Good work', 'Great effort', 'nice work', 'Excellent!',\n",
    "        'Weak', 'Poor effort!', 'not good', 'poor work', 'Could have done better.']\n",
    "\n",
    "labels = np.array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 3], [3, 9], [9, 4], [7, 9], [7], [5], [6, 4], [7, 3], [6, 9], [3, 8, 3, 2]]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "own_embedding_vocab_size = 10\n",
    "encoded_docs_oe = [one_hot(d, own_embedding_vocab_size) for d in docs]\n",
    "print(encoded_docs_oe)\n",
    "print(len(encoded_docs_oe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 3 0 0 0]\n",
      " [3 9 0 0 0]\n",
      " [9 4 0 0 0]\n",
      " [7 9 0 0 0]\n",
      " [7 0 0 0 0]\n",
      " [5 0 0 0 0]\n",
      " [6 4 0 0 0]\n",
      " [7 3 0 0 0]\n",
      " [6 9 0 0 0]\n",
      " [3 8 3 2 0]]\n",
      "(10, 5)\n"
     ]
    }
   ],
   "source": [
    "maxlen = 5\n",
    "padded_decs_oe = pad_sequences(encoded_docs_oe, maxlen=maxlen, padding='post')\n",
    "print(padded_decs_oe)\n",
    "print(padded_decs_oe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=own_embedding_vocab_size, output_dim=32, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(32,activation='relu',recurrent_dropout=0.1,return_sequences)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 5, 32)             320       \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                16640     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 17,025\n",
      "Trainable params: 17,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])  # Compile the model\n",
    "print(model.summary())  # Summarize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.153 Accuracy: 0.900\n"
     ]
    }
   ],
   "source": [
    "model.fit(padded_decs_oe, labels, epochs=50, verbose=0)  # Fit the model\n",
    "loss, accuracy = model.evaluate(padded_decs_oe, labels, verbose=0)  # Evaluate the model\n",
    "print('loss : %0.3f'%loss ,'Accuracy: %0.3f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 9, 0, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_decs_oe[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"Good work\"\n",
    "word_docs_oe = [one_hot(word, own_embedding_vocab_size)]\n",
    "word_oe = pad_sequences(word_docs_oe, maxlen=maxlen, padding='post')\n",
    "pred = model.predict(word_oe)\n",
    "np.round(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = padded_decs_oe\n",
    "a = model.predict(s)\n",
    "np.round(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 9, 0, 0, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_oe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25155085],\n",
       "       [0.88942003],\n",
       "       [0.9993516 ],\n",
       "       [0.9988058 ],\n",
       "       [0.76390016],\n",
       "       [0.39815846],\n",
       "       [0.0150933 ],\n",
       "       [0.34821892],\n",
       "       [0.0957509 ],\n",
       "       [0.00982311]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = padded_decs_oe\n",
    "a = model.predict(s)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "- 분류 : 감정분류 ( 긍 부 정 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 125   68    2    2   15  349  165    2   98    5    4  228    9   43\n",
      "    2 1157   15  299  120    5  120  174   11  220  175  136   50    9\n",
      "    2  228    2    5    2  656  245    2    5    4    2  131  152  491\n",
      "   18    2   32    2 1212   14    9    6  371   78   22  625   64 1382\n",
      "    9    8  168  145   23    4 1690   15   16    4 1355    5   28    6\n",
      "   52  154  462   33   89   78  285   16  145   95]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense,Dropout,LSTM, Embedding,Flatten\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "vocab_size = 2000\n",
    "maxlen=80\n",
    "dictionary = imdb.get_word_index(path='imdb_word_index.json')\n",
    "dictionary = {value:key for key,value in zip(dictionary.keys(),dictionary.values())}\n",
    "\n",
    "(x_train, y_train), (x_test,y_test) = imdb.load_data(num_words = vocab_size)\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen,padding='post')\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen,padding='post')\n",
    "print(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 : better\t68 : were\t2 : and\t2 : and\t15 : for\t349 : budget\t165 : look\t2 : and\t98 : any\t5 : to\t4 : of\t228 : making\t9 : it\t43 : out\t2 : and\t1157 : follows\t15 : for\t299 : effects\t120 : show\t5 : to\t120 : show\t174 : cast\t11 : this\t220 : family\t175 : us\t136 : scenes\t50 : more\t9 : it\t2 : and\t228 : making\t2 : and\t5 : to\t2 : and\t656 : finds\t245 : tv\t2 : and\t5 : to\t4 : of\t2 : and\t131 : these\t152 : thing\t491 : wants\t18 : but\t2 : and\t32 : an\t2 : and\t1212 : cult\t14 : as\t9 : it\t6 : is\t371 : video\t78 : do\t22 : you\t625 : david\t64 : see\t1382 : scenery\t9 : it\t8 : in\t168 : few\t145 : those\t23 : are\t4 : of\t1690 : ship\t15 : for\t16 : with\t4 : of\t1355 : wild\t5 : to\t28 : one\t6 : is\t52 : very\t154 : work\t462 : dark\t33 : they\t89 : don't\t78 : do\t285 : dvd\t16 : with\t145 : those\t95 : them\t"
     ]
    }
   ],
   "source": [
    "for i in x_train[1]:\n",
    "    print(i, ':', dictionary[i], end='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size,output_dim=128,input_length=maxlen))\n",
    "model.add(LSTM(128,dropout = 0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['acc'])\n",
    "\n",
    "che = 'keras_model1'\n",
    "point = ModelCheckpoint(filepath=che , monitor='val_loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 128)           256000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 387,713\n",
      "Trainable params: 387,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "604/782 [======================>.......] - ETA: 16s - loss: 0.4208 - acc: 0.8087"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=32, epochs=10,validation_data = (x_test, y_test),callbacks=[point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('keras_model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_train[1])\n",
    "print(np.round(pred),y_train[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
