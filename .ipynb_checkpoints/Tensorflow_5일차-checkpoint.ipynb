{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lyt09\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense,Dropout,LSTM, Embedding,Flatten,Bidirectional\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "vocab_size = 35000\n",
    "maxlen=100\n",
    "dictionary_word = imdb.get_word_index(path='imdb_word_index.json')\n",
    "dictionary_index = {value:key for key,value in zip(dictionary_word.keys(),dictionary_word.values())}\n",
    "stopwords_ = stopwords.words('english')\n",
    "\n",
    "(x_train, y_train), (x_test,y_test) = imdb.load_data(num_words = vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_idx=[]\n",
    "for idx in stopwords_:\n",
    "    try:\n",
    "        stopwords_idx.append(dictionary_word[idx])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_preprocessing(stopwords_idx,x_train):\n",
    "    x_train_pre = [np.array(x) for x in x_train]\n",
    "    x_train_pre = np.array(x_train_pre)\n",
    "\n",
    "    for word in stopwords_idx:\n",
    "        for idx,x in enumerate(x_train_pre):\n",
    "            x_train_pre[idx] = np.delete(x,np.where(x==word))\n",
    "    return x_train_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = word_preprocessing(stopwords_idx,x_train)\n",
    "x_test = word_preprocessing(stopwords_idx,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  194  1153   194  8255   228  1463  4369  5012   715  1634   394   954\n",
      "   189   102   207   110  3103   188     7   249    93   114  2300  1523\n",
      "   647   116  8163   229   340  1322  4901    19  1002   952    37   455\n",
      "  1543   398  1649  6853   163  3215 10156  1153   194   775     7  8255\n",
      " 11596   349  2637   148   605 15358  8003   123   125 23141  6853   349\n",
      "   165  4362   228  1157   299   120   120   174   220   175   136  4373\n",
      "   228  8255 25249   656   245  2350  9837   152   491  7464  1212   371\n",
      "   625    64  1382  1690  1355    28   154   462   285     0     0     0\n",
      "     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen,padding='post')\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen,padding='post')\n",
    "print(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194 : thought\n",
      "1153 : solid\n",
      "194 : thought\n",
      "8255 : senator\n",
      "228 : making\n",
      "1463 : spot\n",
      "4369 : nomination\n",
      "5012 : assumed\n",
      "715 : jack\n",
      "1634 : picked\n",
      "394 : getting\n",
      "954 : hands\n",
      "189 : fact\n",
      "102 : characters\n",
      "207 : always\n",
      "110 : life\n",
      "3103 : thrillers\n",
      "188 : can't\n",
      "7 : br\n",
      "249 : sure\n",
      "93 : way\n",
      "114 : little\n",
      "2300 : strongly\n",
      "1523 : random\n",
      "647 : view\n",
      "116 : love\n",
      "8163 : principles\n",
      "229 : guy\n",
      "340 : used\n",
      "1322 : producer\n",
      "4901 : icon\n",
      "19 : film\n",
      "1002 : outside\n",
      "952 : unique\n",
      "37 : like\n",
      "455 : direction\n",
      "1543 : imagination\n",
      "398 : keep\n",
      "1649 : queen\n",
      "6853 : diverse\n",
      "163 : makes\n",
      "3215 : stretch\n",
      "10156 : stefan\n",
      "1153 : solid\n",
      "194 : thought\n",
      "775 : begins\n",
      "7 : br\n",
      "8255 : senator\n",
      "11596 : machinations\n",
      "349 : budget\n",
      "2637 : worthwhile\n",
      "148 : though\n",
      "605 : ok\n",
      "15358 : brokedown\n",
      "8003 : awaiting\n",
      "123 : ever\n",
      "125 : better\n",
      "23141 : lugia\n",
      "6853 : diverse\n",
      "349 : budget\n",
      "165 : look\n",
      "4362 : kicked\n",
      "228 : making\n",
      "1157 : follows\n",
      "299 : effects\n",
      "120 : show\n",
      "120 : show\n",
      "174 : cast\n",
      "220 : family\n",
      "175 : us\n",
      "136 : scenes\n",
      "4373 : severe\n",
      "228 : making\n",
      "8255 : senator\n",
      "25249 : levant's\n",
      "656 : finds\n",
      "245 : tv\n",
      "2350 : tend\n",
      "9837 : emerged\n",
      "152 : thing\n",
      "491 : wants\n",
      "7464 : beckinsale\n",
      "1212 : cult\n",
      "371 : video\n",
      "625 : david\n",
      "64 : see\n",
      "1382 : scenery\n",
      "1690 : ship\n",
      "1355 : wild\n",
      "28 : one\n",
      "154 : work\n",
      "462 : dark\n",
      "285 : dvd\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d83a91f2fb88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m':'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "for i in x_train[1]:\n",
    "    print(i, ':', dictionary_index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size,output_dim=128,input_length=maxlen))\n",
    "model.add(Bidirectional(GRU(128, recurrent_dropout=0.2,return_sequences=True)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Bidirectional(GRU(64, recurrent_dropout=0.2,return_sequences=True)))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['acc'])\n",
    "\n",
    "che = 'keras_model.h5'\n",
    "point = ModelCheckpoint(filepath=che , monitor='val_loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 128)          4480000   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 100, 256)          198144    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 100, 256)          1024      \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 100, 128)          123648    \n",
      "_________________________________________________________________\n",
      "seq_self_attention_3 (SeqSel (None, None, 128)         8257      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 1)           129       \n",
      "=================================================================\n",
      "Total params: 4,811,202\n",
      "Trainable params: 4,810,690\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.3569 - acc: 0.8400\n",
      "Epoch 00001: val_loss improved from inf to 0.33135, saving model to keras_model.h5\n",
      "782/782 [==============================] - 375s 479ms/step - loss: 0.3569 - acc: 0.8400 - val_loss: 0.3314 - val_acc: 0.8574\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1602 - acc: 0.9394\n",
      "Epoch 00002: val_loss did not improve from 0.33135\n",
      "782/782 [==============================] - 380s 486ms/step - loss: 0.1602 - acc: 0.9394 - val_loss: 0.3787 - val_acc: 0.8481\n",
      "Epoch 3/10\n",
      "137/782 [====>.........................] - ETA: 4:48 - loss: 0.0559 - acc: 0.9803"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=32, epochs=10,validation_data = (x_test, y_test),callbacks=[point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input Tensor(\"embedding_2_input:0\", shape=(None, 100), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
      "[[[1.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]] 0\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_train[1])\n",
    "print(np.round(pred),y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194 : thought / predict :  1\n",
      "1153 : solid / predict :  0\n",
      "194 : thought / predict :  1\n",
      "8255 : senator / predict :  0\n",
      "228 : making / predict :  1\n",
      "1463 : spot / predict :  0\n",
      "4369 : nomination / predict :  1\n",
      "5012 : assumed / predict :  1\n",
      "715 : jack / predict :  1\n",
      "1634 : picked / predict :  0\n",
      "394 : getting / predict :  0\n",
      "954 : hands / predict :  0\n",
      "189 : fact / predict :  0\n",
      "102 : characters / predict :  0\n",
      "207 : always / predict :  0\n",
      "110 : life / predict :  1\n",
      "3103 : thrillers / predict :  1\n",
      "188 : can't / predict :  1\n",
      "7 : br / predict :  1\n",
      "249 : sure / predict :  0\n",
      "93 : way / predict :  1\n",
      "114 : little / predict :  0\n",
      "2300 : strongly / predict :  0\n",
      "1523 : random / predict :  0\n",
      "647 : view / predict :  0\n",
      "116 : love / predict :  1\n",
      "8163 : principles / predict :  0\n",
      "229 : guy / predict :  0\n",
      "340 : used / predict :  0\n",
      "1322 : producer / predict :  0\n",
      "4901 : icon / predict :  1\n",
      "19 : film / predict :  1\n",
      "1002 : outside / predict :  0\n",
      "952 : unique / predict :  1\n",
      "37 : like / predict :  1\n",
      "455 : direction / predict :  1\n",
      "1543 : imagination / predict :  1\n",
      "398 : keep / predict :  1\n",
      "1649 : queen / predict :  0\n",
      "6853 : diverse / predict :  0\n",
      "163 : makes / predict :  0\n",
      "3215 : stretch / predict :  0\n",
      "10156 : stefan / predict :  0\n",
      "1153 : solid / predict :  0\n",
      "194 : thought / predict :  1\n",
      "775 : begins / predict :  1\n",
      "7 : br / predict :  1\n",
      "8255 : senator / predict :  0\n",
      "11596 : machinations / predict :  1\n",
      "349 : budget / predict :  1\n",
      "2637 : worthwhile / predict :  0\n",
      "148 : though / predict :  0\n",
      "605 : ok / predict :  1\n",
      "15358 : brokedown / predict :  1\n",
      "8003 : awaiting / predict :  1\n",
      "123 : ever / predict :  1\n",
      "125 : better / predict :  0\n",
      "23141 : lugia / predict :  1\n",
      "6853 : diverse / predict :  0\n",
      "349 : budget / predict :  1\n",
      "165 : look / predict :  1\n",
      "4362 : kicked / predict :  1\n",
      "228 : making / predict :  1\n",
      "1157 : follows / predict :  0\n",
      "299 : effects / predict :  1\n",
      "120 : show / predict :  0\n",
      "120 : show / predict :  0\n",
      "174 : cast / predict :  1\n",
      "220 : family / predict :  0\n",
      "175 : us / predict :  1\n",
      "136 : scenes / predict :  1\n",
      "4373 : severe / predict :  1\n",
      "228 : making / predict :  1\n",
      "8255 : senator / predict :  0\n",
      "25249 : levant's / predict :  1\n",
      "656 : finds / predict :  1\n",
      "245 : tv / predict :  1\n",
      "2350 : tend / predict :  1\n",
      "9837 : emerged / predict :  1\n",
      "152 : thing / predict :  0\n",
      "491 : wants / predict :  1\n",
      "7464 : beckinsale / predict :  0\n",
      "1212 : cult / predict :  0\n",
      "371 : video / predict :  1\n",
      "625 : david / predict :  0\n",
      "64 : see / predict :  0\n",
      "1382 : scenery / predict :  0\n",
      "1690 : ship / predict :  0\n",
      "1355 : wild / predict :  1\n",
      "28 : one / predict :  0\n",
      "154 : work / predict :  0\n",
      "462 : dark / predict :  1\n",
      "285 : dvd / predict :  1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-139a38eb4f4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m':'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'predict : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "pred1 = np.round(pred)\n",
    "pred1 = pred1.reshape(-1).astype('int')\n",
    "\n",
    "for i,pred in zip(x_train[1],pred1):\n",
    "    print(i, ':', dictionary_index[i],'/', 'predict : ', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 38s 48ms/step - loss: 1.1495 - acc: 0.8179\n",
      "테스트 정확도 : 0.8179\n"
     ]
    }
   ],
   "source": [
    "print('테스트 정확도 : %.4f'% (model.evaluate(x_test,y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
