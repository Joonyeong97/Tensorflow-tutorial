{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lyt09\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense,Dropout,LSTM, Embedding,Flatten\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "vocab_size = 35000\n",
    "maxlen=100\n",
    "dictionary_word = imdb.get_word_index(path='imdb_word_index.json')\n",
    "dictionary_index = {value:key for key,value in zip(dictionary_word.keys(),dictionary_word.values())}\n",
    "stopwords_ = stopwords.words('english')\n",
    "\n",
    "(x_train, y_train), (x_test,y_test) = imdb.load_data(num_words = vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_idx=[]\n",
    "for idx in stopwords_:\n",
    "    try:\n",
    "        stopwords_idx.append(dictionary_word[idx])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_preprocessing(stopwords_idx,x_train):\n",
    "    x_train_pre = [np.array(x) for x in x_train]\n",
    "    x_train_pre = np.array(x_train_pre)\n",
    "\n",
    "    for word in stopwords_idx:\n",
    "        for idx,x in enumerate(x_train_pre):\n",
    "            x_train_pre[idx] = np.delete(x,np.where(x==word))\n",
    "    return x_train_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = word_preprocessing(stopwords_idx,x_train)\n",
    "x_test = word_preprocessing(stopwords_idx,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  194  1153   194  8255   228  1463  4369  5012   715  1634   394   954\n",
      "   189   102   207   110  3103   188     7   249    93   114  2300  1523\n",
      "   647   116  8163   229   340  1322  4901    19  1002   952    37   455\n",
      "  1543   398  1649  6853   163  3215 10156  1153   194   775     7  8255\n",
      " 11596   349  2637   148   605 15358  8003   123   125 23141  6853   349\n",
      "   165  4362   228  1157   299   120   120   174   220   175   136  4373\n",
      "   228  8255 25249   656   245  2350  9837   152   491  7464  1212   371\n",
      "   625    64  1382  1690  1355    28   154   462   285     0     0     0\n",
      "     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen,padding='post')\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen,padding='post')\n",
    "print(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194 : thought\n",
      "1153 : solid\n",
      "194 : thought\n",
      "8255 : senator\n",
      "228 : making\n",
      "1463 : spot\n",
      "4369 : nomination\n",
      "5012 : assumed\n",
      "715 : jack\n",
      "1634 : picked\n",
      "394 : getting\n",
      "954 : hands\n",
      "189 : fact\n",
      "102 : characters\n",
      "207 : always\n",
      "110 : life\n",
      "3103 : thrillers\n",
      "188 : can't\n",
      "7 : br\n",
      "249 : sure\n",
      "93 : way\n",
      "114 : little\n",
      "2300 : strongly\n",
      "1523 : random\n",
      "647 : view\n",
      "116 : love\n",
      "8163 : principles\n",
      "229 : guy\n",
      "340 : used\n",
      "1322 : producer\n",
      "4901 : icon\n",
      "19 : film\n",
      "1002 : outside\n",
      "952 : unique\n",
      "37 : like\n",
      "455 : direction\n",
      "1543 : imagination\n",
      "398 : keep\n",
      "1649 : queen\n",
      "6853 : diverse\n",
      "163 : makes\n",
      "3215 : stretch\n",
      "10156 : stefan\n",
      "1153 : solid\n",
      "194 : thought\n",
      "775 : begins\n",
      "7 : br\n",
      "8255 : senator\n",
      "11596 : machinations\n",
      "349 : budget\n",
      "2637 : worthwhile\n",
      "148 : though\n",
      "605 : ok\n",
      "15358 : brokedown\n",
      "8003 : awaiting\n",
      "123 : ever\n",
      "125 : better\n",
      "23141 : lugia\n",
      "6853 : diverse\n",
      "349 : budget\n",
      "165 : look\n",
      "4362 : kicked\n",
      "228 : making\n",
      "1157 : follows\n",
      "299 : effects\n",
      "120 : show\n",
      "120 : show\n",
      "174 : cast\n",
      "220 : family\n",
      "175 : us\n",
      "136 : scenes\n",
      "4373 : severe\n",
      "228 : making\n",
      "8255 : senator\n",
      "25249 : levant's\n",
      "656 : finds\n",
      "245 : tv\n",
      "2350 : tend\n",
      "9837 : emerged\n",
      "152 : thing\n",
      "491 : wants\n",
      "7464 : beckinsale\n",
      "1212 : cult\n",
      "371 : video\n",
      "625 : david\n",
      "64 : see\n",
      "1382 : scenery\n",
      "1690 : ship\n",
      "1355 : wild\n",
      "28 : one\n",
      "154 : work\n",
      "462 : dark\n",
      "285 : dvd\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d83a91f2fb88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m':'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "for i in x_train[1]:\n",
    "    print(i, ':', dictionary_index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size,output_dim=128,input_length=maxlen))\n",
    "model.add(LSTM(128,dropout = 0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['acc'])\n",
    "\n",
    "che = 'keras_model.h5'\n",
    "point = ModelCheckpoint(filepath=che , monitor='val_loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 128)          4480000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 4,611,713\n",
      "Trainable params: 4,611,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.4416 - acc: 0.7992\n",
      "Epoch 00001: val_loss improved from inf to 0.37573, saving model to keras_model1\n",
      "WARNING:tensorflow:From C:\\Users\\lyt09\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\lyt09\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: keras_model1\\assets\n",
      "782/782 [==============================] - 132s 169ms/step - loss: 0.4416 - acc: 0.7992 - val_loss: 0.3757 - val_acc: 0.8507\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.2180 - acc: 0.9233\n",
      "Epoch 00002: val_loss did not improve from 0.37573\n",
      "782/782 [==============================] - 128s 164ms/step - loss: 0.2180 - acc: 0.9233 - val_loss: 0.3889 - val_acc: 0.8494\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1278 - acc: 0.9600\n",
      "Epoch 00003: val_loss did not improve from 0.37573\n",
      "782/782 [==============================] - 128s 163ms/step - loss: 0.1278 - acc: 0.9600 - val_loss: 0.4280 - val_acc: 0.8446\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1081 - acc: 0.9701\n",
      "Epoch 00004: val_loss did not improve from 0.37573\n",
      "782/782 [==============================] - 127s 162ms/step - loss: 0.1081 - acc: 0.9701 - val_loss: 0.5234 - val_acc: 0.8354\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0865 - acc: 0.9751\n",
      "Epoch 00005: val_loss did not improve from 0.37573\n",
      "782/782 [==============================] - 136s 173ms/step - loss: 0.0865 - acc: 0.9751 - val_loss: 0.6054 - val_acc: 0.8301\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0714 - acc: 0.9798\n",
      "Epoch 00006: val_loss did not improve from 0.37573\n",
      "782/782 [==============================] - 144s 185ms/step - loss: 0.0714 - acc: 0.9798 - val_loss: 0.6176 - val_acc: 0.8331\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0751 - acc: 0.9772\n",
      "Epoch 00007: val_loss did not improve from 0.37573\n",
      "782/782 [==============================] - 133s 170ms/step - loss: 0.0751 - acc: 0.9772 - val_loss: 0.6880 - val_acc: 0.8236\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0414 - acc: 0.9869\n",
      "Epoch 00008: val_loss did not improve from 0.37573\n",
      "782/782 [==============================] - 134s 171ms/step - loss: 0.0414 - acc: 0.9869 - val_loss: 0.7017 - val_acc: 0.8285\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0295 - acc: 0.9910- ETA: 0s - loss: 0.0296 - acc: 0.\n",
      "Epoch 00009: val_loss did not improve from 0.37573\n",
      "782/782 [==============================] - 141s 180ms/step - loss: 0.0295 - acc: 0.9910 - val_loss: 0.7758 - val_acc: 0.8215\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0219 - acc: 0.9951\n",
      "Epoch 00010: val_loss did not improve from 0.37573\n",
      "782/782 [==============================] - 137s 175ms/step - loss: 0.0219 - acc: 0.9951 - val_loss: 0.7232 - val_acc: 0.8311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c177932520>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=32, epochs=10,validation_data = (x_test, y_test),callbacks=[point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input Tensor(\"embedding_input:0\", shape=(None, 100), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] 0\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_train[1])\n",
    "print(np.round(pred),y_train[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194 : thought / predict :  0\n",
      "1153 : solid / predict :  0\n",
      "194 : thought / predict :  0\n",
      "8255 : senator / predict :  0\n",
      "228 : making / predict :  0\n",
      "1463 : spot / predict :  1\n",
      "4369 : nomination / predict :  1\n",
      "5012 : assumed / predict :  1\n",
      "715 : jack / predict :  1\n",
      "1634 : picked / predict :  1\n",
      "394 : getting / predict :  0\n",
      "954 : hands / predict :  0\n",
      "189 : fact / predict :  0\n",
      "102 : characters / predict :  0\n",
      "207 : always / predict :  0\n",
      "110 : life / predict :  1\n",
      "3103 : thrillers / predict :  0\n",
      "188 : can't / predict :  1\n",
      "7 : br / predict :  0\n",
      "249 : sure / predict :  0\n",
      "93 : way / predict :  0\n",
      "114 : little / predict :  0\n",
      "2300 : strongly / predict :  1\n",
      "1523 : random / predict :  0\n",
      "647 : view / predict :  0\n",
      "116 : love / predict :  0\n",
      "8163 : principles / predict :  0\n",
      "229 : guy / predict :  0\n",
      "340 : used / predict :  0\n",
      "1322 : producer / predict :  0\n",
      "4901 : icon / predict :  1\n",
      "19 : film / predict :  1\n",
      "1002 : outside / predict :  1\n",
      "952 : unique / predict :  0\n",
      "37 : like / predict :  1\n",
      "455 : direction / predict :  1\n",
      "1543 : imagination / predict :  1\n",
      "398 : keep / predict :  1\n",
      "1649 : queen / predict :  0\n",
      "6853 : diverse / predict :  0\n",
      "163 : makes / predict :  0\n",
      "3215 : stretch / predict :  1\n",
      "10156 : stefan / predict :  1\n",
      "1153 : solid / predict :  0\n",
      "194 : thought / predict :  0\n",
      "775 : begins / predict :  1\n",
      "7 : br / predict :  0\n",
      "8255 : senator / predict :  0\n",
      "11596 : machinations / predict :  0\n",
      "349 : budget / predict :  0\n",
      "2637 : worthwhile / predict :  1\n",
      "148 : though / predict :  1\n",
      "605 : ok / predict :  1\n",
      "15358 : brokedown / predict :  1\n",
      "8003 : awaiting / predict :  1\n",
      "123 : ever / predict :  1\n",
      "125 : better / predict :  0\n",
      "23141 : lugia / predict :  1\n",
      "6853 : diverse / predict :  0\n",
      "349 : budget / predict :  0\n",
      "165 : look / predict :  1\n",
      "4362 : kicked / predict :  0\n",
      "228 : making / predict :  0\n",
      "1157 : follows / predict :  0\n",
      "299 : effects / predict :  0\n",
      "120 : show / predict :  0\n",
      "120 : show / predict :  0\n",
      "174 : cast / predict :  0\n",
      "220 : family / predict :  1\n",
      "175 : us / predict :  1\n",
      "136 : scenes / predict :  1\n",
      "4373 : severe / predict :  1\n",
      "228 : making / predict :  0\n",
      "8255 : senator / predict :  0\n",
      "25249 : levant's / predict :  1\n",
      "656 : finds / predict :  0\n",
      "245 : tv / predict :  0\n",
      "2350 : tend / predict :  0\n",
      "9837 : emerged / predict :  1\n",
      "152 : thing / predict :  0\n",
      "491 : wants / predict :  1\n",
      "7464 : beckinsale / predict :  0\n",
      "1212 : cult / predict :  1\n",
      "371 : video / predict :  0\n",
      "625 : david / predict :  0\n",
      "64 : see / predict :  0\n",
      "1382 : scenery / predict :  1\n",
      "1690 : ship / predict :  0\n",
      "1355 : wild / predict :  0\n",
      "28 : one / predict :  1\n",
      "154 : work / predict :  0\n",
      "462 : dark / predict :  0\n",
      "285 : dvd / predict :  1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-92b28aae668f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m':'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'predict : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "pred1 = np.round(pred)\n",
    "pred1 = pred1.reshape(-1).astype('int')\n",
    "\n",
    "for i,pred in zip(x_train[1],pred1):\n",
    "    print(i, ':', dictionary_index[i],'/', 'predict : ', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 10s 13ms/step - loss: 0.7232 - acc: 0.8311\n",
      "테스트 정확도 : 0.8311\n"
     ]
    }
   ],
   "source": [
    "print('테스트 정확도 : %.4f'% (model.evaluate(x_test,y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
